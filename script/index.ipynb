{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QPushButton, QWidget, QLabel, QGridLayout, QTextEdit, QMessageBox, QComboBox\n",
    "from PyQt5.QtGui import QFont, QImage, QPixmap\n",
    "from PyQt5.QtCore import Qt\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shutil\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "\n",
    "K = tf.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameToAdd = \"\"\n",
    "person_id_make_data = 0\n",
    "list_of_person = []\n",
    "data_path = \"../data/\"\n",
    "brut_path = \"../data/brut/\"\n",
    "resize_path = \"../data/resize/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "if not os.path.exists(brut_path):\n",
    "    os.makedirs(brut_path)\n",
    "\n",
    "if not os.path.exists(resize_path):\n",
    "    os.makedirs(resize_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addImage(person_ID, person_NAME, img_ID, face_IMG_file_name, dataset): #Ajoute un fichier et toutes ses informations au dataframe. (Insère une ligne)\n",
    "    new_row = {\n",
    "        'person_id': person_ID,\n",
    "        'person_name': person_NAME,\n",
    "        'img_id': img_ID,\n",
    "        'face_img_file_name': face_IMG_file_name\n",
    "        }\n",
    "    dataset = dataset.append(new_row, ignore_index=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faces = { #Colonnes du dataframe\n",
    "    'person_id': [],\n",
    "    'person_name': [],\n",
    "    'img_id': [],\n",
    "    'face_img_file_name': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(folder_path, person_id_make_data, name, data): #Crée le dataframe\n",
    "\n",
    "    dataframe = pd.DataFrame(data)\n",
    "    person_id_link = []\n",
    "    \n",
    "    persons = os.listdir(folder_path)\n",
    "    \n",
    "    images_files_names = os.listdir(folder_path)\n",
    "    \n",
    "    id_name_tuple = (person_id_make_data, name)\n",
    "    person_id_link.append(id_name_tuple)\n",
    "    \n",
    "    for image_index in range(len(images_files_names)):\n",
    "        img_file_name = images_files_names[image_index]\n",
    "        image_id = int(img_file_name.split('_')[-1].split('.')[0])\n",
    "        face_image_file_name = folder_path + \"/\" + persons[image_index]\n",
    "        \n",
    "        dataframe = addImage(\n",
    "            person_ID = person_id_make_data,\n",
    "            person_NAME = name,\n",
    "            img_ID = image_id,\n",
    "            face_IMG_file_name = face_image_file_name,\n",
    "            dataset = dataframe\n",
    "        )\n",
    "    person_id_make_data += 1\n",
    "    dataframe = dataframe.astype({'person_id': 'int32'})\n",
    "    dataframe = dataframe.astype({'img_id': 'int32'})\n",
    "    list_of_person.append(name)\n",
    "    dataframe.to_csv(\"df_faces.csv\", index=False, header=True)\n",
    "    return dataframe, person_id_make_data, list_of_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_image(image): #Renvoie l'image d'entrée en niveau de gris\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(list_of_images): #Normalise les images\n",
    "    l = len(list_of_images)\n",
    "    for i in range(l):\n",
    "        list_of_images[i] = list_of_images[i]/255.\n",
    "    return list_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y, gray): #Rend les données utilisables par le modèle. gray ---> booléen, True si on veut les images en niveau de gris, False pour RGB.\n",
    "    if gray:\n",
    "        for i in range(len(X)):\n",
    "            X[i] = gray_image(X[i])\n",
    "        X = np.asarray(X)\n",
    "        X = X/255.\n",
    "        X = X.reshape(X.shape[0], 224, 224, 1)\n",
    "    else:\n",
    "        X = normalize_images(X)\n",
    "        X = np.asarray(X)\n",
    "        X = X.reshape(X.shape[0], 224, 224, 3)\n",
    "    y = to_categorical(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df): #Entrée: dataframe et chemin du dossier data. Renvoie X (les images) et y (les labels).\n",
    "    IDs = list(df['person_id'])\n",
    "    FILEs = list(df['face_img_file_name'])\n",
    "    number_of_images = len(IDs)\n",
    "\n",
    "    print(IDs)\n",
    "    print(FILEs)\n",
    "    print(number_of_images)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for index in range(number_of_images):\n",
    "        ID = int(IDs[index])\n",
    "        file_path = FILEs[index]\n",
    "        image = plt.imread(file_path)\n",
    "        X.append(image)\n",
    "        y.append(ID)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model_tf(input_shape, nombre_classes):\n",
    "    resnet = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    resnet.tbatch_sizenable = False\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nombre_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.7, \n",
    "                                            min_lr=0.00000000001)\n",
    "    return model, learning_rate_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x, data_format=None, version=1):\n",
    "    x_temp = np.copy(x)\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    assert data_format in {'channels_last', 'channels_first'}\n",
    "\n",
    "    if version == 1:\n",
    "        if data_format == 'channels_first':\n",
    "            x_temp = x_temp[:, ::-1, ...]\n",
    "            x_temp[:, 0, :, :] -= 93.5940\n",
    "            x_temp[:, 1, :, :] -= 104.7624\n",
    "            x_temp[:, 2, :, :] -= 129.1863\n",
    "        else:\n",
    "            x_temp = x_temp[..., ::-1]\n",
    "            x_temp[..., 0] -= 93.5940\n",
    "            x_temp[..., 1] -= 104.7624\n",
    "            x_temp[..., 2] -= 129.1863\n",
    "\n",
    "    elif version == 2:\n",
    "        if data_format == 'channels_first':\n",
    "            x_temp = x_temp[:, ::-1, ...]\n",
    "            x_temp[:, 0, :, :] -= 91.4953\n",
    "            x_temp[:, 1, :, :] -= 103.8827\n",
    "            x_temp[:, 2, :, :] -= 131.0912\n",
    "        else:\n",
    "            x_temp = x_temp[..., ::-1]\n",
    "            x_temp[..., 0] -= 91.4953\n",
    "            x_temp[..., 1] -= 103.8827\n",
    "            x_temp[..., 2] -= 131.0912\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return x_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_case(array,indice) : #Supprime la case d'un tableau selon sa position\n",
    "    newArray = []\n",
    "    l = len(array)\n",
    "    for i in range(l) :\n",
    "        if indice != i :\n",
    "            newArray = newArray + [array[i]]\n",
    "    return newArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minimum(array) : #Renvoie la position de la plus petite valeur dans un tableau\n",
    "    l = len(array)\n",
    "    position = 0\n",
    "    minimum = array[0]\n",
    "    for i in range(1, l) :\n",
    "        if array[i] < minimum :\n",
    "            position = i\n",
    "            minimum = array[i]\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_arrays(array1, array2) : #Trie array2 selon array1 dans l'ordre croissant\n",
    "    newArray1 = []\n",
    "    newArray2 = []\n",
    "    l = len(array1)\n",
    "    for i in range(l) :\n",
    "        posMinimum = find_minimum(array1)\n",
    "        newArray1 = newArray1 + [array1[posMinimum]]\n",
    "        newArray2 = newArray2 + [array2[posMinimum]]\n",
    "        array1 = delete_case(array1, posMinimum)\n",
    "        array2 = delete_case(array2, posMinimum)\n",
    "    return newArray1, newArray2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize(files_list):\n",
    "    num_list = []\n",
    "    for fileName in files_list:\n",
    "        number = int(fileName.split('.')[0].split(' ')[-1])\n",
    "        num_list.append(number)\n",
    "    \n",
    "    num_list, files_list = sort_arrays(num_list, files_list)\n",
    "    return files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_global_folder(folder_name):\n",
    "    if \"_FACES\" in folder_name:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_names():\n",
    "    #names_list = []\n",
    "    folders = os.listdir(brut_path)\n",
    "    folders = filter(is_global_folder, folders)\n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renvoie le nom d'un fichier sans son extension.\n",
    "def getRidOfExtenstion(fileName):\n",
    "    return fileName.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renvoie l'image du visage d'une personne sur l'image entrée en paramètre.\n",
    "def getCroppedFace(image):\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector(gray, 0)\n",
    "    if len(faces) == 1:\n",
    "        for face in faces:\n",
    "            face_bounding_box = face_utils.rect_to_bb(face)\n",
    "            if all(i >= 0 for i in face_bounding_box):\n",
    "                [x, y, w, h] = face_bounding_box\n",
    "                frame = image[y:y + h, x:x + w]\n",
    "                frame = cv2.resize(frame, (224, 224))\n",
    "                return frame\n",
    "    else:\n",
    "        return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatPictures(name):\n",
    "    total_pictures = 0\n",
    "    detected_faces = 0\n",
    "    pathToFolder = brut_path + name\n",
    "    images_files = os.listdir(pathToFolder) #Liste de toutes les images.jpg de cette personne.\n",
    "    number_of_images = len(images_files)\n",
    "    face_images = []\n",
    "    face_images_files_names = []\n",
    "    for image_number in range(number_of_images):\n",
    "        total_pictures += 1\n",
    "        image_file_name = str(images_files[image_number])\n",
    "        image_real_number = image_file_name.split(' ')[-1].split('.')[0] #On recupere le numero de l'image à partir du nom du fichier.\n",
    "        image_path = pathToFolder + '/' + image_file_name\n",
    "        image = plt.imread(image_path)\n",
    "        cropped_face = getCroppedFace(image) #On récupère le visage sur la photo.\n",
    "        \n",
    "        if type(cropped_face) != int: #Si un seul visage a été trouvé sur la photo.\n",
    "            detected_faces += 1\n",
    "            face_images.append(cropped_face)\n",
    "            face_image_file_name = name + \"_face_\" + image_real_number + \".jpg\"\n",
    "            face_images_files_names.append(face_image_file_name)\n",
    "    \n",
    "    if len(face_images) != 0: #Si au moins un visage a été détecté sur toutes les photos de la personne.\n",
    "        path_face_folder = resize_path + name + \"_FACES\"\n",
    "        os.mkdir(path_face_folder) #Création du dossier qui va contenir les photos de tous ses visages.\n",
    "        for face_image_index in range(len(face_images)):\n",
    "            path_to_write = path_face_folder + \"/\" + face_images_files_names[face_image_index]\n",
    "            try:\n",
    "                cv2.imwrite(path_to_write, cv2.cvtColor(face_images[face_image_index], cv2.COLOR_RGB2BGR)) #Création du fichier .jpg.\n",
    "            except:\n",
    "                pass\n",
    "    message = str(detected_faces) + \" faces detected on \" + str(total_pictures) + \" pictures.\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness(img, value):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWindow(QMainWindow): #Fenetre principale\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "        self.camActivated = False\n",
    "        self.identification = \"Unknown\"\n",
    "        self.explore_index = 0\n",
    "        self.explore_list = []\n",
    "        self.explore_filepath = \"\"\n",
    "        self.explore_name = \"\"\n",
    "\n",
    "    def fit_model(self,df_faces,person_id_make_data):\n",
    "        name = os.listdir(resize_path)\n",
    "        if (len(name) != 0):\n",
    "            for e in name :\n",
    "                df_faces, person_id_make_data, list_of_person = make_data(resize_path + e, person_id_make_data, e.split(\"_\")[0], df_faces)\n",
    "            X, y = get_data(df_faces)\n",
    "\n",
    "            gray_images = False # Mettre True pour avoir les images en niveau de gris, False pour RGB\n",
    "            X, y = preprocess_data(X, y, gray_images)\n",
    "\n",
    "            cnn_model, learning_rate_reduction= resnet_model_tf((224, 224, 3), len(os.listdir(resize_path)))\n",
    "            cnn_model.fit(X, y, epochs=3, verbose=1, callbacks=[learning_rate_reduction])\n",
    "            cnn_model.save(data_path + \"cnn_model\")\n",
    "        else :\n",
    "            self.popup = QMessageBox(QMessageBox.Information,'Message',\"Cannot fit\")\n",
    "            self.popup.show()\n",
    "    \n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Camera')\n",
    "        \n",
    "        self.layout = QGridLayout()\n",
    "        \n",
    "        self.screen = QLabel(\"\")\n",
    "        self.screen.setMinimumHeight(640)\n",
    "        self.screen.setMinimumWidth(800)\n",
    "        self.screen.setMaximumHeight(640)\n",
    "        self.screen.setMaximumWidth(800)\n",
    "        self.screen.setStyleSheet('background-color: black')\n",
    "        self.layout.addWidget(self.screen, 0, 0, 1, 2)\n",
    "        \n",
    "        self.camButton = QPushButton(\"Activate Camera\")\n",
    "        self.camButton.setMinimumHeight(70)\n",
    "        self.camButton.setMinimumWidth(397)\n",
    "        self.camButton.setMaximumHeight(70)\n",
    "        self.camButton.setMaximumWidth(397)\n",
    "        self.camButton.setStyleSheet('background-color: darkgreen')\n",
    "        self.camButton.setFont(QFont('Arial Black', 15))\n",
    "        self.camButton.clicked.connect(self.camInteraction)\n",
    "        self.layout.addWidget(self.camButton, 1, 0)\n",
    "        \n",
    "        self.takePicButton = QPushButton(\"Take Pictures\")\n",
    "        self.takePicButton.setMinimumHeight(70)\n",
    "        self.takePicButton.setMinimumWidth(397)\n",
    "        self.takePicButton.setMaximumHeight(70)\n",
    "        self.takePicButton.setMaximumWidth(397)\n",
    "        self.takePicButton.setStyleSheet('background-color: forestgreen')\n",
    "        self.takePicButton.setFont(QFont('Arial Black', 15))\n",
    "        self.takePicButton.clicked.connect(self.takePictures)\n",
    "        self.layout.addWidget(self.takePicButton, 1, 1)\n",
    "        self.takePicButton.setVisible(False)\n",
    "        \n",
    "        self.explore = QPushButton(\"Explore\")\n",
    "        self.explore.setMinimumHeight(70)\n",
    "        self.explore.setMinimumWidth(397)\n",
    "        self.explore.setMaximumHeight(70)\n",
    "        self.explore.setMaximumWidth(397)\n",
    "        self.explore.setStyleSheet('background-color: grey')\n",
    "        self.explore.setFont(QFont('Arial Black', 15))\n",
    "        self.explore.clicked.connect(self.exploring)\n",
    "        self.layout.addWidget(self.explore, 1, 1)\n",
    "        \n",
    "        self.nameZone = QTextEdit(\"\")\n",
    "        self.nameZone.setMinimumHeight(47)\n",
    "        self.nameZone.setMinimumWidth(800)\n",
    "        self.nameZone.setMaximumHeight(47)\n",
    "        self.nameZone.setMaximumWidth(800)\n",
    "        self.nameZone.setStyleSheet('background-color: lightgrey')\n",
    "        self.nameZone.setFont(QFont('Arial', 18))\n",
    "        self.layout.addWidget(self.nameZone, 2, 0, 1, 2)\n",
    "        self.nameZone.setVisible(False)\n",
    "        \n",
    "        self.explore_layout = QGridLayout() ##################################### EXPLORE\n",
    "        \n",
    "        self.buttons_LR_layout = QGridLayout()\n",
    "        \n",
    "        self.names = QComboBox()\n",
    "        self.names.setMinimumHeight(50)\n",
    "        self.names.setMinimumWidth(380)\n",
    "        self.names.setMaximumHeight(50)\n",
    "        self.names.setMaximumWidth(380)\n",
    "        self.names.setFont(QFont('Arial', 14))\n",
    "        self.names.setStyleSheet('background-color: lightsteelblue')\n",
    "        self.explore_layout.addWidget(self.names, 0, 0)\n",
    "        \n",
    "        self.search = QPushButton(\"Search\")\n",
    "        self.search.setMinimumHeight(50)\n",
    "        self.search.setMinimumWidth(120)\n",
    "        self.search.setMaximumHeight(50)\n",
    "        self.search.setMaximumWidth(120)\n",
    "        self.search.setStyleSheet('background-color: seagreen')\n",
    "        self.search.setFont(QFont('Arial Black', 15))\n",
    "        self.search.clicked.connect(self.search_explore)\n",
    "        self.buttons_LR_layout.addWidget(self.search, 0, 0)\n",
    "        \n",
    "        self.left_explore = QPushButton(\"<\")\n",
    "        self.left_explore.setMinimumHeight(50)\n",
    "        self.left_explore.setMinimumWidth(120)\n",
    "        self.left_explore.setMaximumHeight(50)\n",
    "        self.left_explore.setMaximumWidth(120)\n",
    "        self.left_explore.setStyleSheet('background-color: royalblue')\n",
    "        self.left_explore.setFont(QFont('Arial Black', 15))\n",
    "        self.left_explore.clicked.connect(self.left_exploring)\n",
    "        self.buttons_LR_layout.addWidget(self.left_explore, 0, 1)\n",
    "        \n",
    "        self.right_explore = QPushButton(\">\")\n",
    "        self.right_explore.setMinimumHeight(50)\n",
    "        self.right_explore.setMinimumWidth(120)\n",
    "        self.right_explore.setMaximumHeight(50)\n",
    "        self.right_explore.setMaximumWidth(120)\n",
    "        self.right_explore.setStyleSheet('background-color: royalblue')\n",
    "        self.right_explore.setFont(QFont('Arial Black', 15))\n",
    "        self.right_explore.clicked.connect(self.right_exploring)\n",
    "        self.buttons_LR_layout.addWidget(self.right_explore, 0, 2)\n",
    "        \n",
    "        self.buttons_LR_widget = QWidget()\n",
    "        self.buttons_LR_widget.setLayout(self.buttons_LR_layout)\n",
    "        self.explore_layout.addWidget(self.buttons_LR_widget, 0, 1)\n",
    "        \n",
    "        self.file_name_zone = QLabel(\"File Name\")\n",
    "        self.file_name_zone.setMinimumHeight(50)\n",
    "        self.file_name_zone.setMinimumWidth(380)\n",
    "        self.file_name_zone.setMaximumHeight(50)\n",
    "        self.file_name_zone.setMaximumWidth(380)\n",
    "        self.file_name_zone.setStyleSheet('background-color: lightgrey')\n",
    "        self.file_name_zone.setFont(QFont('Arial Black', 15))\n",
    "        self.explore_layout.addWidget(self.file_name_zone, 1, 0)\n",
    "        \n",
    "        self.quit_explore = QPushButton(\"Quit\")\n",
    "        self.quit_explore.setMinimumHeight(50)\n",
    "        self.quit_explore.setMinimumWidth(380)\n",
    "        self.quit_explore.setMaximumHeight(50)\n",
    "        self.quit_explore.setMaximumWidth(380)\n",
    "        self.quit_explore.setStyleSheet('background-color: firebrick')\n",
    "        self.quit_explore.setFont(QFont('Arial Black', 15))\n",
    "        self.quit_explore.clicked.connect(self.quit_exploring)\n",
    "        self.explore_layout.addWidget(self.quit_explore, 1, 1)\n",
    "        \n",
    "        self.explore_widget = QWidget()\n",
    "        self.explore_widget.setLayout(self.explore_layout)\n",
    "        self.layout.addWidget(self.explore_widget, 3, 0, 1, 2)\n",
    "        self.explore_widget.setVisible(False)\n",
    "        \n",
    "        ######################################################################### END EXPLORE\n",
    "        \n",
    "        self.widget = QWidget()\n",
    "        self.widget.setLayout(self.layout)\n",
    "        self.setCentralWidget(self.widget)\n",
    "        \n",
    "        self.setFixedSize(822, 800)\n",
    "        self.move(700, 100)\n",
    "        \n",
    "    def camInteraction(self):\n",
    "        if not self.camActivated:\n",
    "            self.screen.setStyleSheet('background-color: grey')\n",
    "            self.camButton.setStyleSheet('background-color: darkred')\n",
    "            self.camButton.setText(\"Deactivate Camera\")\n",
    "            #self.takePicButton.setStyleSheet('background-color: forestgreen')\n",
    "            self.explore.setVisible(False)\n",
    "            self.takePicButton.setVisible(True)\n",
    "            self.nameZone.setVisible(True)\n",
    "            self.camActivated = True\n",
    "            self.cap = cv2.VideoCapture(1) ###\n",
    "            \n",
    "            face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "            if os.path.exists(data_path +  \"cnn_model\"):\n",
    "                cnn_model = keras.models.load_model(data_path +  \"cnn_model\")\n",
    "                check_model = True\n",
    "            else :\n",
    "                cnn_model = Sequential()\n",
    "                check_model = False\n",
    "\n",
    "            while self.camActivated == True:\n",
    "                ret, cv_img = self.cap.read()\n",
    "\n",
    "                ##################################################### PARTIE DETECTION DE VISAGE\n",
    "                \n",
    "                gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                face_detector = dlib.get_frontal_face_detector()\n",
    "                faces = face_detector(gray, 0)\n",
    "\n",
    "                for face in faces:\n",
    "                    face_bounding_box = face_utils.rect_to_bb(face)\n",
    "                    if all(i >= 0 for i in face_bounding_box):\n",
    "                        [x, y, w, h] = face_bounding_box\n",
    "                        frame = cv_img[y:y + h, x:x + w]\n",
    "                        cv2.rectangle(cv_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        frame = cv2.resize(frame, (224, 224))\n",
    "                        frame = np.asarray(frame, dtype=np.float64)\n",
    "                        frame = np.expand_dims(frame, axis=0)\n",
    "                        # frame = preprocess_input(frame)\n",
    "                        \n",
    "                        name = \"Unknown\"\n",
    "                        if (check_model):\n",
    "                            prediction = cnn_model.predict(frame)\n",
    "                            \n",
    "                            max_value = max(prediction[0])\n",
    "\n",
    "                            index = prediction[0].tolist().index(max_value)\n",
    "\n",
    "                            print(max_value)\n",
    "                            if (max_value > 0.7):\n",
    "                                name = list_of_person[index]\n",
    "                            \n",
    "                        font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                        cv2.putText(cv_img, name, (x, y-5), font_face, 0.8, (0,0,255), 3)\n",
    "\n",
    "                ################################################################################\n",
    "                frame = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "                qimage = QImage(frame, frame.shape[1], frame.shape[0], QImage.Format_RGB888)\n",
    "                pixmap = QPixmap(qimage)\n",
    "                pixmap = pixmap.scaled(960,640, Qt.KeepAspectRatio)\n",
    "                self.screen.setPixmap(pixmap)\n",
    "                cv2.waitKey(1)\n",
    "            self.cap.release()\n",
    "        else:\n",
    "            im_np = np.zeros((960,540,1))\n",
    "            qimage = QImage(im_np, im_np.shape[1], im_np.shape[0], QImage.Format_RGB888)\n",
    "            pixmap = QPixmap(qimage)    \n",
    "            pixmap = pixmap.scaled(640,400, Qt.KeepAspectRatio)\n",
    "            self.screen.setPixmap(pixmap)\n",
    "            self.screen.setStyleSheet('background-color: black')\n",
    "            self.camButton.setStyleSheet('background-color: darkgreen')\n",
    "            #self.takePicButton.setStyleSheet('background-color: grey')\n",
    "            self.takePicButton.setVisible(False)\n",
    "            self.explore.setVisible(True)\n",
    "            self.camButton.setText(\"Activate Camera\")\n",
    "            self.nameZone.setVisible(False)\n",
    "            self.camActivated = False\n",
    "    \n",
    "    def takePictures(self):\n",
    "        if self.camActivated:\n",
    "            name = self.nameZone.toPlainText()\n",
    "            if name == \"\":\n",
    "                self.popup = QMessageBox(QMessageBox.Information,'Message','Please enter your name first.')\n",
    "                self.popup.show()\n",
    "            else:\n",
    "                self.nameZone.setText(\"\")\n",
    "                folders = os.listdir(\"./\")\n",
    "                if name not in folders:\n",
    "                    os.mkdir(brut_path + name)\n",
    "                    count = 0\n",
    "                    total = 0\n",
    "                    timeBase = time.time()\n",
    "                    while total < 20:\n",
    "                        retCatch, frameCatch = self.cap.read()\n",
    "                    \n",
    "                        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                        org = (20, 70)\n",
    "                        fontScale = 0.8\n",
    "                        color = (255, 0, 0)\n",
    "                        thickness = 2\n",
    "                        percentage = str(total*5) + \" %\"\n",
    "                    \n",
    "                        cv2.waitKey(1)\n",
    "                    \n",
    "                        count += 1\n",
    "                        actualTime = time.time()\n",
    "                        deltaNeeded = total*0.3\n",
    "                        deltaActual = actualTime - timeBase\n",
    "                        if deltaActual >= deltaNeeded:\n",
    "                            frame = frameCatch\n",
    "                            if total < 5:\n",
    "                                frame = increase_brightness(frameCatch, total * 20)\n",
    "                            if total >=5 and total < 10:\n",
    "                                frame = cv2.blur(frame, (5, 5)) \n",
    "                            cv2.imwrite(os.path.join(brut_path, name + '/' + name + ' ' + str(total) + '.jpg') , frame)\n",
    "                            total += 1\n",
    "                        frameCatch = cv2.cvtColor(frameCatch, cv2.COLOR_BGR2RGB)\n",
    "                        frameOut = cv2.putText(frameCatch, percentage, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                        qimage = QImage(frameOut, frameOut.shape[1], frameOut.shape[0], QImage.Format_RGB888)\n",
    "                        pixmap = QPixmap(qimage)\n",
    "                        pixmap = pixmap.scaled(960,640, Qt.KeepAspectRatio)\n",
    "                        self.screen.setPixmap(pixmap)\n",
    "                        \n",
    "                    \n",
    "                    message = treatPictures(name)\n",
    "                    \n",
    "                    # self.popup = QMessageBox(QMessageBox.Information,'Message',\"Pictures taken!\\n\" + message)\n",
    "                    # self.popup.show()\n",
    "                    self.fit_model(df_faces,person_id_make_data)\n",
    "                else:\n",
    "                    self.popup = QMessageBox(QMessageBox.Information,'Message','Please delete the existing folder.')\n",
    "                    self.popup.show()\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def exploring(self):\n",
    "        self.takePicButton.setVisible(False)\n",
    "        self.camButton.setVisible(False)\n",
    "        self.explore.setVisible(False)\n",
    "        self.explore_widget.setVisible(True)\n",
    "        \n",
    "        folders = define_names()\n",
    "        self.names.clear()\n",
    "        self.names.addItems(folders)\n",
    "        self.file_name_zone.setText(\"File Name\")\n",
    "        \n",
    "    def explore_print(self, filePath): #Affiche la photo à l'ecran selon son path.\n",
    "        image = plt.imread(filePath)\n",
    "        qimage = QImage(image, image.shape[1], image.shape[0], QImage.Format_RGB888)\n",
    "        pixmap = QPixmap(qimage)\n",
    "        pixmap = pixmap.scaled(960,640, Qt.KeepAspectRatio)\n",
    "        fileName = filePath.split(\"/\")[-1]\n",
    "        self.file_name_zone.setText(fileName)\n",
    "        self.screen.setPixmap(pixmap)\n",
    "        \n",
    "    \n",
    "    def left_exploring(self):\n",
    "        self.explore_index -= 1\n",
    "        files_num = len(self.explore_list)\n",
    "        if self.explore_index == -1:\n",
    "            self.explore_index = files_num - 1\n",
    "        self.explore_filepath = brut_path + self.name + \"/\" + self.explore_list[self.explore_index]\n",
    "        self.explore_print(self.explore_filepath)\n",
    "    \n",
    "    def right_exploring(self):\n",
    "        self.explore_index += 1\n",
    "        files_num = len(self.explore_list)\n",
    "        if self.explore_index == files_num:\n",
    "            self.explore_index = 0\n",
    "        self.explore_filepath = brut_path + self.name + \"/\" + self.explore_list[self.explore_index]\n",
    "        self.explore_print(self.explore_filepath)\n",
    "        \n",
    "    \n",
    "    def search_explore(self):\n",
    "        self.name = self.names.currentText()\n",
    "        self.explore_index = 0\n",
    "        self.explore_list = os.listdir(brut_path + self.name)\n",
    "        self.explore_list = reorganize(self.explore_list)\n",
    "        self.explore_filepath = brut_path + self.name + \"/\" + self.explore_list[self.explore_index]\n",
    "        self.explore_print(self.explore_filepath)\n",
    "        print(\"search\")\n",
    "    \n",
    "    def quit_exploring(self):\n",
    "        self.explore_widget.setVisible(False)\n",
    "        self.camButton.setVisible(True)\n",
    "        self.explore.setVisible(True)\n",
    "        im_np = np.zeros((960,540,1))\n",
    "        qimage = QImage(im_np, im_np.shape[1], im_np.shape[0], QImage.Format_RGB888)\n",
    "        pixmap = QPixmap(qimage)\n",
    "        pixmap = pixmap.scaled(640,400, Qt.KeepAspectRatio)\n",
    "        self.screen.setPixmap(pixmap)\n",
    "        self.screen.setStyleSheet('background-color: black')\n",
    "    \n",
    "    def closeEvent(self, event): #Fonction qui se lance lors de la fermeture de la fenetre.\n",
    "        if self.camActivated:\n",
    "            self.cap.release()\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "['../memory/resize/agnes_FACES/agnes_face_1.jpg', '../memory/resize/agnes_FACES/agnes_face_2.jpg', '../memory/resize/agnes_FACES/agnes_face_3.jpg', '../memory/resize/agnes_FACES/agnes_face_4.jpg', '../memory/resize/agnes_FACES/agnes_face_5.jpg', '../memory/resize/agnes_FACES/agnes_face_6.jpg', '../memory/resize/agnes_FACES/agnes_face_7.jpg', '../memory/resize/agnes_FACES/agnes_face_8.jpg', '../memory/resize/agnes_FACES/agnes_face_9.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_0.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_1.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_10.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_11.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_12.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_13.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_14.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_15.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_16.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_17.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_18.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_19.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_2.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_3.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_4.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_5.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_6.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_7.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_8.jpg', '../memory/resize/Jahedul_FACES/Jahedul_face_9.jpg', '../memory/resize/The Rock_FACES/The Rock_face_0.jpg', '../memory/resize/The Rock_FACES/The Rock_face_1.jpg', '../memory/resize/The Rock_FACES/The Rock_face_10.jpg', '../memory/resize/The Rock_FACES/The Rock_face_11.jpg', '../memory/resize/The Rock_FACES/The Rock_face_12.jpg', '../memory/resize/The Rock_FACES/The Rock_face_13.jpg', '../memory/resize/The Rock_FACES/The Rock_face_14.jpg', '../memory/resize/The Rock_FACES/The Rock_face_15.jpg', '../memory/resize/The Rock_FACES/The Rock_face_16.jpg', '../memory/resize/The Rock_FACES/The Rock_face_17.jpg', '../memory/resize/The Rock_FACES/The Rock_face_18.jpg', '../memory/resize/The Rock_FACES/The Rock_face_19.jpg', '../memory/resize/The Rock_FACES/The Rock_face_2.jpg', '../memory/resize/The Rock_FACES/The Rock_face_3.jpg', '../memory/resize/The Rock_FACES/The Rock_face_4.jpg', '../memory/resize/The Rock_FACES/The Rock_face_5.jpg', '../memory/resize/The Rock_FACES/The Rock_face_6.jpg', '../memory/resize/The Rock_FACES/The Rock_face_7.jpg', '../memory/resize/The Rock_FACES/The Rock_face_8.jpg', '../memory/resize/The Rock_FACES/The Rock_face_9.jpg', '../memory/resize/Theo_FACES/Theo_face_0.jpg', '../memory/resize/Theo_FACES/Theo_face_1.jpg', '../memory/resize/Theo_FACES/Theo_face_10.jpg', '../memory/resize/Theo_FACES/Theo_face_11.jpg', '../memory/resize/Theo_FACES/Theo_face_12.jpg', '../memory/resize/Theo_FACES/Theo_face_13.jpg', '../memory/resize/Theo_FACES/Theo_face_14.jpg', '../memory/resize/Theo_FACES/Theo_face_15.jpg', '../memory/resize/Theo_FACES/Theo_face_16.jpg', '../memory/resize/Theo_FACES/Theo_face_17.jpg', '../memory/resize/Theo_FACES/Theo_face_18.jpg', '../memory/resize/Theo_FACES/Theo_face_19.jpg', '../memory/resize/Theo_FACES/Theo_face_2.jpg', '../memory/resize/Theo_FACES/Theo_face_3.jpg', '../memory/resize/Theo_FACES/Theo_face_4.jpg', '../memory/resize/Theo_FACES/Theo_face_5.jpg', '../memory/resize/Theo_FACES/Theo_face_6.jpg', '../memory/resize/Theo_FACES/Theo_face_7.jpg', '../memory/resize/Theo_FACES/Theo_face_8.jpg', '../memory/resize/Theo_FACES/Theo_face_9.jpg']\n",
      "69\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 5, 5, 128)         2359424   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,926,276\n",
      "Trainable params: 25,880,836\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.0566 - accuracy: 0.4638WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "3/3 [==============================] - 20s 4s/step - loss: 3.0566 - accuracy: 0.4638 - lr: 0.0010\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.9275WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "3/3 [==============================] - 15s 4s/step - loss: 0.3953 - accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000   WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "3/3 [==============================] - 16s 4s/step - loss: 0.0020 - accuracy: 1.0000 - lr: 0.0010\n",
      "INFO:tensorflow:Assets written to: cnn_model\\assets\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16920/2827091094.py\u001b[0m in \u001b[0;36mcamInteraction\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[1;31m##################################################### PARTIE DETECTION DE VISAGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m                 \u001b[0mface_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = QApplication(sys.argv)\n",
    "window = MainWindow()\n",
    "window.show()\n",
    "app.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65cb662d2ffd24625b83a185df816dd9ac9360312fec79592fb027d27703f776"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
